{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b410d83e-fb2c-4a62-a8da-0768c295b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import ChatModel, InputOutputTextPair,TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "375bf3bc-bbdf-4cce-bab9-83588d20106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5018ac0-1578-4998-9597-46cc72f8eab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is a type of artificial intelligence (AI) model that can understand and generate human language. LLMs are trained on massive datasets of text and code, and they can learn to perform a wide variety of tasks, such as translating languages, writing different kinds of creative content, and answering your questions in an informative way.\n",
      "\n",
      "LLMs are still under development, but they have the potential to revolutionize many industries. For example, LLMs could be used to create more accurate and personalized customer service experiences, to help doctors diagnose and treat diseases, and to even write entire books and movies.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is a large language model?\"\n",
    "\n",
    "response = generation_model.predict(prompt=prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9603c07d-6f87-4a52-af6a-6f7966caec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Artificial intelligence**\n",
      "2. **Machine learning**\n",
      "3. **Blockchain**\n",
      "4. **Virtual reality**\n",
      "5. **Augmented reality**\n",
      "6. **5G**\n",
      "7. **Edge computing**\n",
      "8. **Internet of things**\n",
      "9. **Self-driving cars**\n",
      "10. **Wearables**\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Create a numbered list of 10 items. Each item in the list should be a trend in the tech industry.\n",
    "\n",
    "Each trend should be less than 5 words.\"\"\" # try your own prompt\n",
    "\n",
    "response = generation_model.predict(prompt=prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e24025-d4e3-4db3-8981-0699e00106d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a15154-2b7e-457e-bd6d-a1f0b8f0a643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiCandidateTextGenerationResponse(text='Yes, Lord of the Rings and Hobbit are both based on book series.', _prediction_response=Prediction(predictions=[{'safetyAttributes': [{'categories': [], 'scores': [], 'blocked': False}], 'candidates': [{'content': 'Yes, Lord of the Rings and Hobbit are both based on book series.', 'author': '1'}], 'citationMetadata': [{'citations': []}]}], deployed_model_id='', model_version_id='', model_resource_name='', explanations=None), is_blocked=False, safety_attributes={}, candidates=[Yes, Lord of the Rings and Hobbit are both based on book series.])\n"
     ]
    }
   ],
   "source": [
    "chat = chat_model.start_chat(\n",
    "    context=\"My name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\",\n",
    "    examples=[\n",
    "        InputOutputTextPair(\n",
    "            input_text=\"Who do you work for?\",\n",
    "            output_text=\"I work for Ned.\",\n",
    "        ),\n",
    "        InputOutputTextPair(\n",
    "            input_text=\"What do I like?\",\n",
    "            output_text=\"Ned likes watching movies.\",\n",
    "        ),\n",
    "    ],\n",
    "    temperature=0.3,\n",
    "    max_output_tokens=200,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ")\n",
    "print(chat.send_message(\"Are my favorite movies based on a book series?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f20fbe-766a-4e69-9568-c90120b4ab13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i really enjoyed the movie last night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so many amazing cinematic scenes yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>had a great time writing my Python scripts a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>huge sense of relief when my .py script finall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O Romeo, Romeo, wherefore art thou Romeo?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0              i really enjoyed the movie last night\n",
       "1         so many amazing cinematic scenes yesterday\n",
       "2  had a great time writing my Python scripts a f...\n",
       "3  huge sense of relief when my .py script finall...\n",
       "4          O Romeo, Romeo, wherefore art thou Romeo?"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text = [\n",
    "    \"i really enjoyed the movie last night\",\n",
    "    \"so many amazing cinematic scenes yesterday\",\n",
    "    \"had a great time writing my Python scripts a few days ago\",\n",
    "    \"huge sense of relief when my .py script finally ran without error\",\n",
    "    \"O Romeo, Romeo, wherefore art thou Romeo?\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(text, columns=[\"text\"])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
